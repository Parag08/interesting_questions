{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7e09f3f29669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mske\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm,  tree, preprocessing, metrics\n",
    "import sklearn.ensemble as ske\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import skflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data as dataframes\n",
    "test_data = pd.read_csv('./test.csv',index_col=False)\n",
    "train_data = pd.read_csv ('./train.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_and_purge(table,colums_to_drop,purge=True):\n",
    "    for col in colums_to_drop:\n",
    "        try:\n",
    "            del table[col]\n",
    "        except KeyError as exp:\n",
    "            print('colum',exp,'not found in table')\n",
    "    if purge:\n",
    "        table.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantise(table,dict_to_quantize):\n",
    "    '''takes table and dict {column_name:[{value_in_table:value_to_replace_with}]}\n",
    "    example:- quantise(table,{Sex:[{male:1},{female:0}]}) will replace male and female in Sex column of table with 1 and 0'''\n",
    "    for val in dict_to_quantize:\n",
    "        for string_to_replace in dict_to_quantize[val]:\n",
    "            value_to_replace_with = dict_to_quantize[val][string_to_replace]\n",
    "            table[val].replace(string_to_replace,value_to_replace_with,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colum 'Name' not found in table\n",
      "colum 'Ticket' not found in table\n",
      "colum 'Cabin' not found in table\n",
      "colum 'Fare' not found in table\n",
      "colum 'Name' not found in table\n",
      "colum 'Ticket' not found in table\n",
      "colum 'Cabin' not found in table\n",
      "colum 'Fare' not found in table\n"
     ]
    }
   ],
   "source": [
    "#test drop_and_purge functions\n",
    "coloums_to_drop = ['Name','Ticket','Cabin','Fare']\n",
    "drop_and_purge(test_data,coloums_to_drop,purge=False)\n",
    "drop_and_purge(train_data,coloums_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch  Embarked  Survived\n",
      "0          892       3    1  34.5      0      0         0       0.0\n",
      "1          893       3    0  47.0      1      0         2       0.0\n",
      "2          894       2    1  62.0      0      0         0       1.0\n",
      "3          895       3    1  27.0      0      0         2       0.0\n",
      "4          896       3    0  22.0      1      1         2       0.0\n",
      "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch  Embarked\n",
      "0            1         0       3    1  22.0      1      0       2.0\n",
      "1            2         1       1    0  38.0      1      0       1.0\n",
      "2            3         1       3    0  26.0      0      0       2.0\n",
      "3            4         1       1    0  35.0      1      0       2.0\n",
      "4            5         0       3    1  35.0      0      0       2.0\n"
     ]
    }
   ],
   "source": [
    "quantise(test_data,{'Sex':{'male':1,'female':0}})\n",
    "quantise(test_data,{'Embarked':{'Q':0,'C':1,'S':2}})\n",
    "quantise(train_data,{'Sex':{'male':1,'female':0}})\n",
    "quantise(train_data,{'Embarked':{'Q':0,'C':1,'S':2}})\n",
    "print(test_data.head())\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453\n",
      "93 195\n"
     ]
    }
   ],
   "source": [
    "data_dist_sex = train_data['Sex'].value_counts()\n",
    "print(data_dist_sex[1])\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "male_survived = 0\n",
    "female_survived = 0\n",
    "for index, row in train_data.iterrows():\n",
    "    if row['Survived'] == 1:\n",
    "        if row['Sex'] == 1:\n",
    "            male_survived = male_survived + 1\n",
    "        else:\n",
    "            female_survived = female_survived + 1\n",
    "print(male_survived,female_survived)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "def survivedCalc(prob):\n",
    "    random = np.random.choice([0, 1], p=[1-prob, prob])\n",
    "    #print(random)\n",
    "    return random\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "perct_male_survived = male_survived/data_dist_sex[1]\n",
    "perct_female_survived = female_survived/data_dist_sex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.   1.  22.   1.   0.   2.]\n",
      " [  1.   0.  38.   1.   0.   1.]\n",
      " [  3.   0.  26.   0.   0.   2.]\n",
      " ..., \n",
      " [  1.   0.  19.   0.   0.   2.]\n",
      " [  1.   1.  26.   0.   0.   1.]\n",
      " [  3.   1.  32.   0.   0.   0.]]\n",
      "[0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1\n",
      " 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1\n",
      " 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1\n",
      " 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0\n",
      " 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1\n",
      " 0 0 0 0 0 0 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9058988764044944"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt = tree.DecisionTreeClassifier(max_depth=10)\n",
    "train_data = train_data.dropna()\n",
    "Y = train_data['Survived'].values\n",
    "X = train_data.drop(['Survived','PassengerId'], axis=1).values\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "clf_dt.fit (X, Y)\n",
    "clf_dt.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in test_data.iterrows():\n",
    "    if row.isnull().values.any() == False:\n",
    "        data = row[[ 'Pclass' , 'Sex','Age','SibSp','Parch','Embarked']]\n",
    "        data = data.values\n",
    "        val = clf_dt.predict(data.reshape(-1,6))\n",
    "        test_data = test_data.set_value(index,'Survived',int(val))\n",
    "    else:\n",
    "        if row['Sex'] == 'male':\n",
    "            val = survivedCalc(perct_male_survived)\n",
    "            test_data = test_data.set_value(index,'Survived',val)\n",
    "        else:\n",
    "            val = survivedCalc(perct_female_survived)\n",
    "            test_data = test_data.set_value(index,'Survived',val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensubmission = test_data[['PassengerId', 'Survived']].copy()\n",
    "gensubmission.Survived = gensubmission.Survived.astype(int)\n",
    "gensubmission.to_csv('./DSsubmission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_model(X, y):\n",
    "    layers = skflow.ops.dnn(X, [20, 40, 20], tf.tanh)\n",
    "    return skflow.models.logistic_regression(layers, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-264627cfc1b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf_clf_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorFlowEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtf_clf_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skflow' is not defined"
     ]
    }
   ],
   "source": [
    "tf_clf_c = skflow.TensorFlowEstimator(model_fn=custom_model, n_classes=2, batch_size=256, steps=1000, learning_rate=0.05)\n",
    "tf_clf_c.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
